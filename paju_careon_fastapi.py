# paju_careon_fastapi.py
# FastAPI + STT + RAG + GPT + TTS + ë§ˆì´í¬ ë²„íŠ¼ HTML (MVP)

import os
os.environ["CT2_USE_CUDNN"] = "0"

import time
import logging
from fastapi import FastAPI, UploadFile, Form
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from openai import OpenAI
from dotenv import load_dotenv
from faster_whisper import WhisperModel
from gtts import gTTS

from rag_service import retrieve_context

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. í™˜ê²½ ì„¤ì • ë° ë¡œê¹…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("paju_fastapi")

load_dotenv()

SKT_API_KEY = os.getenv("ADOTX_API_KEY")
if not SKT_API_KEY:
    raise RuntimeError("ADOTX_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. SKT GPT í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GPT_CLIENT = OpenAI(
    api_key=SKT_API_KEY,
    base_url="https://guest-api.sktax.chat/v1",
)

MODEL = "ax4"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. STT(Whisper) ëª¨ë¸ ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CPUì—ì„œë„ ëŒì•„ê°€ë„ë¡ ê²½ëŸ‰ ì„¤ì •(MVP). GPU ìˆìœ¼ë©´ device="cuda"ë¡œ êµì²´ ê°€ëŠ¥.
# GPU ìˆëŠ” ì„œë²„ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜ (ìŒì„±ì¸ì‹ í€„ë¦¬í‹° ë†’ì´ê¸° ìœ„í•¨)
# STT_MODEL = WhisperModel("small", device="cpu", compute_type="int8")
STT_MODEL = WhisperModel("medium", device="cuda", compute_type="float16")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ íŒŒì£¼ì‹œì²­ì—ì„œ ìš´ì˜í•˜ëŠ” AI ë¯¼ì›Â·ë³µì§€Â·ê±´ê°• ì•ˆë‚´ ìƒë‹´ì‚¬ 'ëŒë´„ì˜¨'ì…ë‹ˆë‹¤.
ì‹œë¯¼ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ë§ë¡œ, íŒŒì£¼ì‹œ ê´€ë ¨ í–‰ì •, ë³µì§€, ê±´ê°• ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ë‹µë³€ ì‹œ ë‹¤ìŒ ì›ì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”:
- ë‹¨ì •ì ì´ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…
- ê´€ë ¨ ë¶€ì„œ, ì „í™”ë²ˆí˜¸, ì œë„ëª…ì´ ìˆì„ ê²½ìš° êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ
- ëª¨ë¥¼ ê²½ìš° "í•´ë‹¹ ì •ë³´ëŠ” íŒŒì£¼ì‹œì²­ ë¯¼ì›ì½œì„¼í„°(031-940-2114)ë¡œ ë¬¸ì˜í•˜ì„¸ìš”."ë¡œ ì•ˆë‚´
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. STT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def speech_to_text(audio_path: str) -> str:
    try:
        segments, _ = STT_MODEL.transcribe(
            audio_path,
            beam_size=5,
            language="ko",            # ğŸ”´ í•œêµ­ì–´ ê³ ì • (ìŒì„±ì¸ì‹ í€„ë¦¬í‹° ì˜¬ë¦¬ê¸° ìœ„í•¨)
            vad_filter=True,          # ğŸ”´ ë¬´ìŒ/ì¡ìŒ ì»·
            temperature=0,            # ğŸ”´ ì˜¨ë„ ë‚®ê²Œ (ê²°ê³¼ ì•ˆì •í™”)
            vad_parameters={"min_silence_duration_ms": 500}
        )
        text = " ".join([seg.text for seg in segments]).strip()
        logger.info(f"[STT ê²°ê³¼]: {text}")
        return text
    except Exception as e:
        logger.error(f"STT ë³€í™˜ ì‹¤íŒ¨: {e}")
        return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. RAG + GPT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_answer_with_rag(query: str) -> str:
    """
    1) queryë¡œ ë¬¸ì„œ ê²€ìƒ‰ (RAG)
    2) contextì™€ í•¨ê»˜ GPT í˜¸ì¶œ
    """
    try:
        context = retrieve_context(query)

        user_prompt = f"""
[íŒŒì£¼ì‹œ ê´€ë ¨ ì°¸ê³  ì •ë³´]
{context if context else "ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì•Œê³  ìˆëŠ” ë²”ìœ„ ë‚´ì—ì„œë§Œ ì•ˆë‚´í•˜ì„¸ìš”."}

[ì‹œë¯¼ ì§ˆë¬¸]
{query}

ìœ„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì•ˆë‚´ ì›ì¹™ì— ë§ê²Œ íŒŒì£¼ì‹œë¯¼ì—ê²Œ ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”.
ëª¨í˜¸í•˜ê±°ë‚˜ í™•ì‹¤í•˜ì§€ ì•Šì€ ë¶€ë¶„ì€ ì„ì˜ë¡œ ì¶”ì¸¡í•˜ì§€ ë§ê³ ,
íŒŒì£¼ì‹œì²­ ì½œì„¼í„°(031-940-2114) ë˜ëŠ” ê´€ë ¨ ë¶€ì„œë¡œ ë¬¸ì˜í•˜ë„ë¡ ì•ˆë‚´í•˜ì„¸ìš”.
"""

        completion = GPT_CLIENT.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
        )
        answer = completion.choices[0].message.content.strip()
        logger.info(f"[ëŒë´„ì˜¨ RAG ì‘ë‹µ]: {answer}")
        return answer
    except Exception as e:
        logger.error(f"GPT(RAG) ì‘ë‹µ ì‹¤íŒ¨: {e}")
        return "í˜„ì¬ ìƒë‹´ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì´ìš©í•´ ì£¼ì„¸ìš”."

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. TTS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def text_to_speech(text: str, out_path: str) -> str:
    try:
        tts = gTTS(text=text, lang="ko")
        tts.save(out_path)
        logger.info(f"[TTS ìƒì„± ì™„ë£Œ]: {out_path}")
        return out_path
    except Exception as e:
        logger.error(f"TTS ë³€í™˜ ì‹¤íŒ¨: {e}")
        return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. FastAPI ì•± ë° ì •ì  íŒŒì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(
    title="íŒŒì£¼ì‹œ ëŒë´„ì˜¨ ì±—ë´‡ API (MVP)",
    description="STT + RAG + GPT + TTS + ë§ˆì´í¬ ë²„íŠ¼ ê¸°ë°˜ ìŒì„± ì±—ë´‡",
    version="0.1.0",
)

# static/tts ë””ë ‰í† ë¦¬ ì¤€ë¹„ (ìŒì„± íŒŒì¼ ì„œë¹™ìš©)
os.makedirs("static/tts", exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9. ì›¹ UI (ë§ˆì´í¬ ë²„íŠ¼ í˜ì´ì§€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/", response_class=HTMLResponse)
async def index():
    """í…ŒìŠ¤íŠ¸ìš© ì›¹ UI"""
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return HTMLResponse(
            "<h1>index.htmlì´ ì—†ìŠµë‹ˆë‹¤. static/index.html ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.</h1>",
            status_code=500,
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10. ìŒì„± ê¸°ë°˜ ëŒ€í™” ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/paju/voice-chat")
async def voice_chat(
    user_id: str = Form("guest"),
    audio: UploadFile | None = None,
):
    if not audio:
        return JSONResponse({"error": "ìŒì„± íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}, status_code=400)

    # 1) ìŒì„± íŒŒì¼ ì„ì‹œ ì €ì¥
    ts = int(time.time())
    tmp_input = f"/tmp/{user_id}_{ts}_{audio.filename}"
    with open(tmp_input, "wb") as f:
        f.write(await audio.read())

    # 2) STT
    query = speech_to_text(tmp_input)
    if not query:
        return JSONResponse({"error": "ìŒì„± ì¸ì‹ ì‹¤íŒ¨"}, status_code=500)

    # 3) RAG + GPT
    answer = generate_answer_with_rag(query)

    # 4) TTS -> static/tts ê²½ë¡œì— ì €ì¥ (ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì ‘ê·¼ ê°€ëŠ¥)
    tts_filename = f"{user_id}_{ts}.mp3"
    tts_path = os.path.join("static", "tts", tts_filename)
    saved_path = text_to_speech(answer, out_path=tts_path)
    if not saved_path:
        return JSONResponse({"error": "TTS ë³€í™˜ ì‹¤íŒ¨"}, status_code=500)

    tts_url = f"/static/tts/{tts_filename}"

    # 5) ê²°ê³¼ ë°˜í™˜ (í”„ë¡ íŠ¸ì—ì„œ ì±„íŒ…+ìŒì„± ì¬ìƒ)
    return JSONResponse(
        {
            "user_id": user_id,
            "recognized_text": query,
            "answer": answer,
            "tts_url": tts_url,
        }
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 11. Uvicorn ì§ì ‘ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("paju_careon_fastapi:app", host="0.0.0.0", port=8903, reload=True)

# ì‹¤í–‰ëª…ë ¹ : uvicorn paju_careon_fastapi:app --reload --port 8903